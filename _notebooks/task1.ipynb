{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n",
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import shapely as shp\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import fynesse\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "import MySQLdb\n",
    "import sklearn\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "import dask as dd\n",
    "import dask_geopandas as ddg\n",
    "\n",
    "# set up database connection\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "\n",
    "with open(\"./credentials1.yaml\") as file:\n",
    "  credentials = yaml.safe_load(file)\n",
    "\n",
    "username = credentials[\"username\"]\n",
    "password = credentials[\"password\"]\n",
    "url = credentials[\"url\"]\n",
    "port = credentials[\"port\"]\n",
    "\n",
    "%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n",
    "\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{username}:{password}@{url}:{port}/ads_2024?local_infile=1\"\n",
    "%sql $connection_string\n",
    "%sql use ads_2024;\n",
    "\n",
    "conn = MySQLdb.connect(host=url, user=username, password=password, database=\"ads_2024\", local_infile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded ./TS062-2021-5.csv\n",
      "Already downloaded ./census2021-ts062.zip\n",
      "Already downloaded ./census2021-ts062-extra.zip\n",
      "Already downloaded ./census2021-ts059.zip\n",
      "Already downloaded ./united_kingdom-latest.osm.pbf\n",
      "Already downloaded ./output_areas.csv\n",
      "Already downloaded ./output_areas.geojson\n",
      "Already downloaded ./counties.geojson\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "\n",
    "for url in [\n",
    "    # 2021 Census data\n",
    "    # NS-SEC\n",
    "    \"https://static.ons.gov.uk/datasets/TS062-2021-5.csv\",\n",
    "    \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts062.zip\",\n",
    "    \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts062-extra.zip\",\n",
    "\n",
    "    # Industry by age categories\n",
    "    # (\"./RM062-2021-3-filtered-2024-11-26T15_05_33Z.csv\", \"https://static.ons.gov.uk/datasets/3195f3da-ba62-4f47-b03a-51f26092371f/RM062-2021-3-filtered-2024-11-26T15:05:33Z.csv#get-data\"),\n",
    "    \"https://www.nomisweb.co.uk/output/census/2021/census2021-ts059.zip\",\n",
    "\n",
    "    # OSM data\n",
    "    \"https://download.openstreetmap.fr/extracts/europe/united_kingdom-latest.osm.pbf\",\n",
    "    \n",
    "    # Geographic data of census output areas\n",
    "    (\"./output_areas.csv\", \"https://open-geography-portalx-ons.hub.arcgis.com/api/download/v1/items/6beafcfd9b9c4c9993a06b6b199d7e6d/csv?layers=0\"),\n",
    "    (\"./output_areas.geojson\", \"https://open-geography-portalx-ons.hub.arcgis.com/api/download/v1/items/6beafcfd9b9c4c9993a06b6b199d7e6d/geojson?layers=0\"),\n",
    "    (\"./counties.geojson\", \"https://open-geography-portalx-ons.hub.arcgis.com/api/download/v1/items/5e0277da82884fd184ff3e1aa55bd414/geojson?layers=0\"),\n",
    "]:\n",
    "\n",
    "    if isinstance(url, tuple):\n",
    "        filename, url = url\n",
    "    else:\n",
    "        filename = f\"./{url.split('/')[-1]}\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {url}\")\n",
    "        r = requests.get(url)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Already downloaded {filename}\")\n",
    "\n",
    "\n",
    "    if filename.endswith('.zip') and not os.path.exists(filename.replace('.zip', '')):\n",
    "        with ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"census2021-ts062-oa.csv\")\n",
    "\n",
    "# the values in \"geography\" and \"geography code\" columns are equal\n",
    "assert (df['geography'] == df['geography code']).all()\n",
    "\n",
    "# the values in \"geography\" column are less than 10 characters\n",
    "assert (df[\"geography\"].str.len() < 10).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS census_nssec (\n",
    "    -- Year of the census\n",
    "    year INT NOT NULL,\n",
    "\n",
    "    -- Geography identifiers \n",
    "    output_area VARCHAR(10) NOT NULL,\n",
    "    \n",
    "    -- Population counts by NS-SEC classification\n",
    "    total_residents_16_and_over INT NOT NULL,\n",
    "    higher_managerial_admin_professional INT NOT NULL,\n",
    "    lower_managerial_admin_professional INT NOT NULL, \n",
    "    intermediate_occupations INT NOT NULL,\n",
    "    small_employers_own_account INT NOT NULL,\n",
    "    lower_supervisory_technical INT NOT NULL,\n",
    "    semi_routine_occupations INT NOT NULL,\n",
    "    routine_occupations INT NOT NULL,\n",
    "    never_worked_longterm_unemployed INT NOT NULL,\n",
    "    full_time_students INT NOT NULL,\n",
    "    \n",
    "    -- Constraints\n",
    "    PRIMARY KEY (year, output_area),\n",
    "    CHECK (total_residents_16_and_over >= 0),\n",
    "    CHECK (higher_managerial_admin_professional >= 0),\n",
    "    CHECK (lower_managerial_admin_professional >= 0),\n",
    "    CHECK (intermediate_occupations >= 0), \n",
    "    CHECK (small_employers_own_account >= 0),\n",
    "    CHECK (lower_supervisory_technical >= 0),\n",
    "    CHECK (semi_routine_occupations >= 0),\n",
    "    CHECK (routine_occupations >= 0),\n",
    "    CHECK (never_worked_longterm_unemployed >= 0),\n",
    "    CHECK (full_time_students >= 0)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\3308575725.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  if pd.read_sql(\"SELECT * FROM census_nssec limit 1\", conn).empty:\n"
     ]
    }
   ],
   "source": [
    "if pd.read_sql(\"SELECT * FROM census_nssec limit 1\", conn).empty:\n",
    "    command = \"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'census2021-ts062-oa.csv' \\\n",
    "    INTO TABLE census_nssec \\\n",
    "    FIELDS TERMINATED BY ',' \\\n",
    "    ENCLOSED BY '\"' \\\n",
    "    LINES TERMINATED BY '\\n' \\\n",
    "    IGNORE 1 LINES \\\n",
    "    (year, output_area, @geocode, total_residents_16_and_over, higher_managerial_admin_professional, lower_managerial_admin_professional, intermediate_occupations, small_employers_own_account, lower_supervisory_technical, semi_routine_occupations, routine_occupations, never_worked_longterm_unemployed, full_time_students);\"\"\"\n",
    "\n",
    "    %sql $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS oas (\n",
    "    year INT NOT NULL,                    -- Year of the census\n",
    "\n",
    "    -- Area codes and names\n",
    "    code VARCHAR(10) NOT NULL,              -- Output Area code\n",
    "    lsoa_code VARCHAR(9) NOT NULL,         -- LSOA code \n",
    "    lsoa_name VARCHAR(100) NOT NULL,       -- LSOA name in English\n",
    "    \n",
    "    -- Geographic coordinates\n",
    "    bng_easting INT NOT NULL,              -- British National Grid Easting\n",
    "    bng_northing INT NOT NULL,             -- British National Grid Northing\n",
    "    latitude DECIMAL(10,8) NOT NULL,       -- Latitude coordinate\n",
    "    longitude DECIMAL(11,8) NOT NULL,      -- Longitude coordinate\n",
    "    \n",
    "    -- Unique identifier\n",
    "    global_id VARCHAR(36) NOT NULL,\n",
    "\n",
    "    -- Geometry\n",
    "    geometry GEOMETRY NOT NULL,            -- Geometry of the output area in WG84\n",
    "    \n",
    "    -- Constraints\n",
    "    PRIMARY KEY (year, code)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\95361804.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  if pd.read_sql(\"SELECT * FROM oas limit 1\", conn).empty:\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"output_areas.csv\"):\n",
    "    output_areas_gdf = gpd.read_file(\"output_areas.geojson\")\n",
    "\n",
    "    # set the default geometry column\n",
    "    output_areas_gdf.set_geometry(\"geometry\", inplace=True)\n",
    "\n",
    "    output_areas_gdf.geometry.set_crs(epsg=27700, inplace=True)\n",
    "    output_areas_gdf.geometry = output_areas_gdf.geometry.to_crs(epsg=4326)\n",
    "    output_areas_gdf.to_csv(\"output_areas.csv\", index=False, sep=\"|\")\n",
    "\n",
    "if pd.read_sql(\"SELECT * FROM oas limit 1\", conn).empty:\n",
    "    command = \"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'output_areas.csv' \\\n",
    "    INTO TABLE oas \\\n",
    "    FIELDS TERMINATED BY '|' \\\n",
    "    OPTIONALLY ENCLOSED BY '\"' \\\n",
    "    LINES TERMINATED BY '\\n' \\\n",
    "    IGNORE 1 LINES \\\n",
    "    (@fid, code, lsoa_code, lsoa_name, @welsh, bng_easting, bng_northing, latitude, longitude, global_id, @geometry) \\\n",
    "    SET geometry = ST_GeomFromText(@geometry, 4326), year = 2021;\"\"\"\n",
    "\n",
    "    %sql $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS hours_worked (\n",
    "    -- Year of the census\n",
    "    year INT NOT NULL,\n",
    "\n",
    "    -- Geography identifiers\n",
    "    output_area VARCHAR(10) NOT NULL,\n",
    "\n",
    "    -- Population counts by hours worked\n",
    "    total_employed_over_16 INT NOT NULL,\n",
    "    part_time INT NOT NULL,\n",
    "    worked_15_hours_or_less INT NOT NULL,\n",
    "    worked_16_to_30_hours INT NOT NULL,\n",
    "    full_time INT NOT NULL,\n",
    "    worked_31_to_48_hours INT NOT NULL,\n",
    "    worked_49_hours_or_more INT NOT NULL,\n",
    "\n",
    "    -- Constraints\n",
    "    PRIMARY KEY (year, output_area),\n",
    "    CHECK (total_employed_over_16 >= 0),\n",
    "    CHECK (part_time >= 0),\n",
    "    CHECK (worked_15_hours_or_less >= 0),\n",
    "    CHECK (worked_16_to_30_hours >= 0),\n",
    "    CHECK (full_time >= 0),\n",
    "    CHECK (worked_31_to_48_hours >= 0),\n",
    "    CHECK (worked_49_hours_or_more >= 0)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\3280249861.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  if pd.read_sql(\"SELECT * FROM hours_worked limit 1\", conn).empty:\n"
     ]
    }
   ],
   "source": [
    "if pd.read_sql(\"SELECT * FROM hours_worked limit 1\", conn).empty:\n",
    "    command = \"\"\"LOAD DATA LOCAL INFILE './census2021-ts059-oa.csv' INTO TABLE `hours_worked` \\\n",
    "    FIELDS TERMINATED BY ',' \\\n",
    "    OPTIONALLY ENCLOSED by '\"' \\\n",
    "    LINES STARTING BY '' \\\n",
    "    TERMINATED BY '\\\\n' \\\n",
    "    IGNORE 1 LINES \\\n",
    "    (year, output_area, @geography_code, \\\n",
    "    total_employed_over_16, part_time, \\\n",
    "    worked_15_hours_or_less, worked_16_to_30_hours, \\\n",
    "    full_time, worked_31_to_48_hours, \\\n",
    "    worked_49_hours_or_more);\"\"\"\n",
    "\n",
    "    %sql $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS osm_features (\n",
    "    -- Unique identifier\n",
    "    osmid INT NOT NULL,\n",
    "\n",
    "    -- Area of the feature\n",
    "    area DOUBLE,\n",
    "\n",
    "    -- Tags\n",
    "    amenity VARCHAR(255),\n",
    "    building VARCHAR(255),\n",
    "    building_use VARCHAR(255),\n",
    "    building_levels INT,\n",
    "    height FLOAT,\n",
    "    shop VARCHAR(255),\n",
    "    leisure VARCHAR(255),\n",
    "    sport VARCHAR(255),\n",
    "    landuse VARCHAR(255),\n",
    "    office VARCHAR(255),\n",
    "    railway VARCHAR(255),\n",
    "    public_transport VARCHAR(255),\n",
    "    highway VARCHAR(255),\n",
    "    aeroway VARCHAR(255),\n",
    "    waterway VARCHAR(255),\n",
    "    man_made VARCHAR(255),\n",
    "\n",
    "    -- Geometry\n",
    "    geometry GEOMETRY NOT NULL,\n",
    "\n",
    "    -- Constraints\n",
    "    PRIMARY KEY (osmid),\n",
    "    CHECK (osmid >= 0)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_height_to_meters(height_series):\n",
    "    def convert_to_meters(height):\n",
    "        if pd.isnull(height):\n",
    "            return None\n",
    "        \n",
    "        height_str = str(height).strip().lower()\n",
    "        pure_number_pattern = r'^([\\d,.]+)\\s*(m|meter|meters|metre|metres|ft|foot|feet)?$'\n",
    "        feet_inches_pattern = r\"^(\\d+)'\\s*(\\d+)?\\\"?$\"\n",
    "        \n",
    "        # Try pure number with optional unit\n",
    "        match = re.match(pure_number_pattern, height_str)\n",
    "        \n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            # Replace comma with dot for decimal conversion if necessary\n",
    "            value = value.replace(',', '.')\n",
    "            \n",
    "            try:\n",
    "                value = float(value)\n",
    "            except ValueError:\n",
    "                return None\n",
    "            \n",
    "            # Define conversion factors\n",
    "            unit = unit.lower() if unit else 'm'  # Assume meters if no unit provided\n",
    "            \n",
    "            if unit in ['m', 'meter', 'meters', 'metre', 'metres']:\n",
    "                return value\n",
    "            elif unit in ['ft', 'foot', 'feet']:\n",
    "                return value * 0.3048  # 1 foot = 0.3048 meters\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        # Try feet and inches pattern\n",
    "        match = re.match(feet_inches_pattern, height_str)\n",
    "        if match:\n",
    "            feet, inches = match.groups()\n",
    "            try:\n",
    "                feet = int(feet)\n",
    "                inches = int(inches) if inches else 0\n",
    "            except ValueError:\n",
    "                return np.nan  # Unable to convert to integers\n",
    "            \n",
    "            total_meters = feet * 0.3048 + inches * 0.0254\n",
    "            return round(total_meters, 4)  # Rounded to 4 decimal places\n",
    "        \n",
    "        # If no pattern matches, return None\n",
    "        return None\n",
    "    \n",
    "    # Apply the conversion to each element in the Series\n",
    "    return height_series.apply(convert_to_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\3375045728.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  if pd.read_sql(\"SELECT * FROM osm_features LIMIT 1\", conn).empty:\n"
     ]
    }
   ],
   "source": [
    "# for each csv file in the osm_features directory, load it into the database\n",
    "\n",
    "if pd.read_sql(\"SELECT * FROM osm_features LIMIT 1\", conn).empty:\n",
    "    for file in os.listdir(\"osm_features\"):\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        name = file.split(\".\")[0]\n",
    "        print(f\"Processing {name}\")\n",
    "\n",
    "        command = f\"\"\"\n",
    "        LOAD DATA LOCAL INFILE 'osm_features/{file}' \\\n",
    "        INTO TABLE osm_features \\\n",
    "        FIELDS TERMINATED BY '|' \\\n",
    "        ENCLOSED BY '\"' \\\n",
    "        LINES TERMINATED BY '\\\\n' \\\n",
    "        IGNORE 1 LINES \\\n",
    "        (osmid, @area, @amenity, @building, @building_use, building_levels, @height, @shop, @leisure, @sport, @landuse, @office, @railway, @public_transport, @highway, @aeroway, @waterway, @man_made, @geo) \\\n",
    "        SET geometry = ST_GeomFromText(@geo, 4326), \\\n",
    "        area = NULLIF(@area, '0.0'), \\\n",
    "        amenity = NULLIF(@amenity, ''), \\\n",
    "        building = NULLIF(@building, ''), \\\n",
    "        building_use = NULLIF(@building_use, ''), \\\n",
    "        shop = NULLIF(@shop, ''), \\\n",
    "        leisure = NULLIF(@leisure, ''), \\\n",
    "        sport = NULLIF(@sport, ''), \\\n",
    "        landuse = NULLIF(@landuse, ''), \\\n",
    "        office = NULLIF(@office, ''), \\\n",
    "        railway = NULLIF(@railway, ''), \\\n",
    "        public_transport = NULLIF(@public_transport, ''), \\\n",
    "        highway = NULLIF(@highway, ''), \\\n",
    "        aeroway = NULLIF(@aeroway, ''), \\\n",
    "        waterway = NULLIF(@waterway, ''), \\\n",
    "        man_made = NULLIF(@man_made, ''), \\\n",
    "        height = NULLIF(@height, 'NaN');\"\"\"\n",
    "\n",
    "        %sql $command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "(pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_output_area'\")\n",
      "[SQL: ALTER TABLE census_nssec ADD INDEX idx_output_area (output_area);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "(pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_geometry'\")\n",
      "[SQL: ALTER TABLE oas ADD SPATIAL INDEX idx_geometry (geometry);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "(pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_output_area'\")\n",
      "[SQL: ALTER TABLE hours_worked ADD INDEX idx_output_area (output_area);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# census nssec table\n",
    "%sql ALTER TABLE census_nssec ADD INDEX idx_output_area (output_area);\n",
    "# output area geometry table\n",
    "%sql ALTER TABLE oas ADD SPATIAL INDEX idx_geometry (geometry);\n",
    "# hours worked\n",
    "%sql ALTER TABLE hours_worked ADD INDEX idx_output_area (output_area);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "(pymysql.err.OperationalError) (1061, \"Duplicate key name 'idx_amenity'\")\n",
      "[SQL: ALTER TABLE osm_features ADD INDEX idx_amenity (amenity),\n",
      "ADD INDEX idx_building (building),\n",
      "ADD INDEX idx_building_use (building_use),\n",
      "ADD INDEX idx_shop (shop),\n",
      "ADD INDEX idx_leisure (leisure),\n",
      "ADD INDEX idx_sport (sport),\n",
      "ADD INDEX idx_landuse (landuse),\n",
      "ADD INDEX idx_office (office),\n",
      "ADD INDEX idx_railway (railway),\n",
      "ADD INDEX idx_public_transport (public_transport),\n",
      "ADD INDEX idx_highway (highway),\n",
      "ADD INDEX idx_aeroway (aeroway),\n",
      "ADD INDEX idx_waterway (waterway),\n",
      "ADD INDEX idx_man_made (man_made),\n",
      "ADD SPATIAL INDEX idx_geometry (geometry);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "ALTER TABLE osm_features ADD INDEX idx_amenity (amenity),\n",
    "ADD INDEX idx_building (building),\n",
    "ADD INDEX idx_building_use (building_use),\n",
    "ADD INDEX idx_shop (shop),\n",
    "ADD INDEX idx_leisure (leisure),\n",
    "ADD INDEX idx_sport (sport),\n",
    "ADD INDEX idx_landuse (landuse),\n",
    "ADD INDEX idx_office (office),\n",
    "ADD INDEX idx_railway (railway),\n",
    "ADD INDEX idx_public_transport (public_transport),\n",
    "ADD INDEX idx_highway (highway),\n",
    "ADD INDEX idx_aeroway (aeroway),\n",
    "ADD INDEX idx_waterway (waterway),\n",
    "ADD INDEX idx_man_made (man_made),\n",
    "ADD SPATIAL INDEX idx_geometry (geometry);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_parallelism = mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_geometry_from_wkt(df, geo_col=\"geometry\", wkt_col=\"wkt\", crs=\"EPSG:4326\"):\n",
    "    df[geo_col] = df[wkt_col].apply(shp.wkt.loads)\n",
    "    df.drop(columns=[wkt_col], inplace=True)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=geo_col, crs=crs)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\705512205.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  oas = load_geometry_from_wkt(pd.read_sql(\"SELECT *, ST_AsText(geometry) as wkt from oas\", conn))\n"
     ]
    }
   ],
   "source": [
    "oas = load_geometry_from_wkt(pd.read_sql(\"SELECT *, ST_AsText(geometry) as wkt from oas\", conn))\n",
    "oas = ddg.from_geopandas(oas, npartitions=available_parallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [\n",
    "    (1000000, 100),\n",
    "    (10000, 1_000),\n",
    "    (5000, 10_000),\n",
    "    (2000, 50_000),\n",
    "    (1000, 1_000_000),\n",
    "    (100, 100_000_000)\n",
    "]\n",
    "\n",
    "for radius, _ in cutoffs:\n",
    "    oas[f\"{radius}m\"] = oas[\"geometry\"].to_crs(epsg=6933).buffer(radius).to_crs(epsg=4326).simplify(radius/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"oa_osm_joined\"):\n",
    "    os.mkdir(\"oa_osm_joined\")\n",
    "\n",
    "def collect_features_for_condition(condition):\n",
    "    filepath = f\"oa_osm_joined/{condition}.csv\"\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"Already processed {condition}, loading from file...\")\n",
    "        return ddg.from_geopandas(gpd.read_file(filepath, sep=\"|\", index=False), npartitions=available_parallelism)\n",
    "    else:\n",
    "        gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n",
    "        size = len(gdf)\n",
    "\n",
    "        print(f\"{condition}\")\n",
    "        print(f\"Found {size} features\")\n",
    "\n",
    "        for r, cutoff in cutoffs:\n",
    "            if size < cutoff:\n",
    "                radius = r\n",
    "                break\n",
    "\n",
    "        print(f\"Looking within {radius}m\")\n",
    "\n",
    "        joined = gdf.sjoin(oas.set_geometry(f\"{radius}m\"), predicate=\"intersects\")\n",
    "        joined = joined.compute()\n",
    "        joined.drop(columns=[i for i in joined.columns if i.endswith(\"m\")], inplace=True)\n",
    "\n",
    "        print(f\"Found {len(df)} relationships, saving...\")\n",
    "        joined.to_csv(filepath, index=False, sep=\"|\")\n",
    "        return joined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\2050792218.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%university%'\n",
      "Found 963 features\n",
      "Looking within 10000m\n",
      "Found 188880 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\2050792218.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%research_institute%'\n",
      "Found 54 features\n",
      "Looking within 1000000m\n",
      "Found 188880 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\2050792218.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%college%'\n",
      "Found 1143 features\n",
      "Looking within 5000m\n",
      "Found 188880 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_26568\\2050792218.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%library%'\n",
      "Found 2358 features\n",
      "Looking within 5000m\n"
     ]
    }
   ],
   "source": [
    "university_buildings = collect_features_for_condition(r\"amenity like '%university%'\")\n",
    "research_institutes = collect_features_for_condition(r\"amenity like '%research_institute%'\")\n",
    "college_buildings = collect_features_for_condition(r\"amenity like '%college%'\")\n",
    "libraries = collect_features_for_condition(r\"amenity like '%library%'\")\n",
    "\n",
    "other_education = collect_features_for_condition(r\"amenity like '%school%' or amenity like '%kindergarten%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%cafe%' or amenity like '%coffee_shop%'\n",
      "Found 11099 features\n",
      "Looking within 2000m\n",
      "Found 1141670 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%bar%' or amenity like '%pub%'\n",
      "Found 24130 features\n",
      "Looking within 2000m\n",
      "Found 1941374 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%restaurant%'\n",
      "Found 12293 features\n",
      "Looking within 2000m\n",
      "Found 1496525 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%fast_food%'\n",
      "Found 13876 features\n",
      "Looking within 2000m\n",
      "Found 1516475 relationships, saving...\n"
     ]
    }
   ],
   "source": [
    "cafes_and_coffee_shops = collect_features_for_condition(r\"amenity like '%cafe%' or amenity like '%coffee_shop%'\")\n",
    "bars_and_pubs = collect_features_for_condition(r\"amenity like '%bar%' or amenity like '%pub%'\")\n",
    "restaurants = collect_features_for_condition(r\"amenity like '%restaurant%'\")\n",
    "fast_food = collect_features_for_condition(r\"amenity like '%fast_food%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%cinema%'\n",
      "Found 413 features\n",
      "Looking within 10000m\n",
      "Found 485395 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%theatre%'\n",
      "Found 1028 features\n",
      "Looking within 5000m\n",
      "Found 504597 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%nightclub%' or amenity like '%music_venue%'\n",
      "Found 481 features\n",
      "Looking within 10000m\n",
      "Found 726196 relationships, saving...\n"
     ]
    }
   ],
   "source": [
    "cinemas = collect_features_for_condition(r\"amenity like '%cinema%'\")\n",
    "theatres = collect_features_for_condition(r\"amenity like '%theatre%'\")\n",
    "nightclubs_and_music_venues = collect_features_for_condition(r\"amenity like '%nightclub%' or amenity like '%music_venue%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leisure like '%gym%' or leisure like '%sports_centre%' or leisure like '%fitness%' or sport is not null\n",
      "Found 121958 features\n",
      "Looking within 1000m\n",
      "Found 2272545 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\3682709614.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gyms_and_sports_centres \u001b[38;5;241m=\u001b[39m collect_features_for_condition(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleisure like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%g\u001b[39;00m\u001b[38;5;124mym\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or leisure like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124mports_centre\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or leisure like \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124mitness\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or sport is not null\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m parks_playgrounds_and_gardens \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_features_for_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleisure like \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mpark\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m or leisure like \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mplayground\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m or leisure like \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%g\u001b[39;49;00m\u001b[38;5;124;43marden\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[70], line 11\u001b[0m, in \u001b[0;36mcollect_features_for_condition\u001b[1;34m(condition)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlready processed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loading from file...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ddg\u001b[38;5;241m.\u001b[39mfrom_geopandas(gpd\u001b[38;5;241m.\u001b[39mread_file(filepath, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), npartitions\u001b[38;5;241m=\u001b[39mavailable_parallelism)\n\u001b[1;32m---> 11\u001b[0m gdf \u001b[38;5;241m=\u001b[39m ddg\u001b[38;5;241m.\u001b[39mfrom_geopandas(\u001b[43mload_geometry_from_wkt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSELECT *, ST_AsText(geometry) as wkt from osm_features where \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcondition\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, npartitions\u001b[38;5;241m=\u001b[39mavailable_parallelism)\n\u001b[0;32m     12\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(gdf)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m, in \u001b[0;36mload_geometry_from_wkt\u001b[1;34m(df, geo_col, wkt_col, crs)\u001b[0m\n\u001b[0;32m      2\u001b[0m df[geo_col] \u001b[38;5;241m=\u001b[39m df[wkt_col]\u001b[38;5;241m.\u001b[39mapply(shp\u001b[38;5;241m.\u001b[39mwkt\u001b[38;5;241m.\u001b[39mloads)\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[wkt_col], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGeoDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeo_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gdf\n",
      "File \u001b[1;32mc:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:192\u001b[0m, in \u001b[0;36mGeoDataFrame.__init__\u001b[1;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    185\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(geometry, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m geometry\u001b[38;5;241m.\u001b[39mcrs\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m crs\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m geometry\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m==\u001b[39m crs\n\u001b[0;32m    189\u001b[0m     ):\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(crs_mismatch_error)\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m crs:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssigning CRS to a GeoDataFrame without a geometry column is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Supply geometry using the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword argument, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor by providing a DataFrame with column name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:352\u001b[0m, in \u001b[0;36mGeoDataFrame.set_geometry\u001b[1;34m(self, col, drop, inplace, crs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     level\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m crs\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# Check that we are using a listlike of geometries\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m level \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# update _geometry_column_name prior to assignment\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;66;03m# to avoid default is None warning\u001b[39;00m\n\u001b[0;32m    355\u001b[0m frame\u001b[38;5;241m.\u001b[39m_geometry_column_name \u001b[38;5;241m=\u001b[39m geo_column_name\n",
      "File \u001b[1;32mc:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:57\u001b[0m, in \u001b[0;36m_ensure_geometry\u001b[1;34m(data, crs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Series):\n\u001b[1;32m---> 57\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_shapely\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m GeoSeries(out, index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\array.py:159\u001b[0m, in \u001b[0;36mfrom_shapely\u001b[1;34m(data, crs)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_shapely\u001b[39m(data, crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Convert a list or array of shapely objects to a GeometryArray.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(\u001b[43mvectorized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_shapely\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, crs\u001b[38;5;241m=\u001b[39mcrs)\n",
      "File \u001b[1;32mc:\\Users\\varun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\_vectorized.py:136\u001b[0m, in \u001b[0;36mfrom_shapely\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    134\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(_shapely_to_pygeos(geom))\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(geom)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(geom, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    138\u001b[0m     geom \u001b[38;5;241m=\u001b[39m shapely\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mshape(geom)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gyms_and_sports_centres = collect_features_for_condition(r\"leisure like '%gym%' or leisure like '%sports_centre%' or leisure like '%fitness%' or sport is not null\")\n",
    "parks_playgrounds_and_gardens = collect_features_for_condition(r\"leisure like '%park%' or leisure like '%playground%' or leisure like '%garden%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop like '%bookstore%' or shop like '%copyshop%'\n",
      "Found 254 features\n",
      "Looking within 8000m\n",
      "Found 316199 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop like '%supermarket%' or shop like '%convenience%'\n",
      "Found 20059 features\n",
      "Looking within 1000m\n",
      "Found 648890 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop like '%clothing%'\n",
      "Found 9 features\n",
      "Looking within 1000000m\n",
      "Found 1699900 relationships, saving...\n"
     ]
    }
   ],
   "source": [
    "bookstores_and_copyshops = collect_features_for_condition(r\"shop like '%bookstore%' or shop like '%copyshop%'\")\n",
    "supermarkets_and_convenience_stores = collect_features_for_condition(r\"shop like '%supermarket%' or shop like '%convenience%'\")\n",
    "clothing_stores = collect_features_for_condition(r\"shop like '%clothing%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway like '%bus_stop%' or highway like '%bus_station%' or amenity like '%bus_station%' or public_transport like '%bus%'\n",
      "Found 729 features\n",
      "Looking within 8000m\n",
      "Found 428121 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "railway like '%station%' or railway like '%subway%' or public_transport like '%train%' or public_transport like '%subway%'\n",
      "Found 12 features\n",
      "Looking within 1000000m\n",
      "Found 2266555 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroway like '%aerodrome%' or aeroway like '%airport%'\n",
      "Found 347 features\n",
      "Looking within 8000m\n",
      "Found 65256 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%taxi%' or public_transport like '%taxi%'\n",
      "Found 460 features\n",
      "Looking within 8000m\n",
      "Found 487342 relationships, saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_15716\\4040773087.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  gdf = ddg.from_geopandas(load_geometry_from_wkt(pd.read_sql(f\"SELECT *, ST_AsText(geometry) as wkt from osm_features where {condition}\", conn)), npartitions=available_parallelism)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amenity like '%bicycle%'\n",
      "Found 3308 features\n",
      "Looking within 4000m\n",
      "Found 1015847 relationships, saving...\n"
     ]
    }
   ],
   "source": [
    "bus_stops_and_stations = collect_features_for_condition(r\"highway like '%bus_stop%' or highway like '%bus_station%' or amenity like '%bus_station%' or public_transport like '%bus%'\")\n",
    "train_and_subway_stations = collect_features_for_condition(r\"railway like '%station%' or railway like '%subway%' or public_transport like '%train%' or public_transport like '%subway%'\")\n",
    "airports = collect_features_for_condition(r\"aeroway like '%aerodrome%' or aeroway like '%airport%'\")\n",
    "taxi_stands = collect_features_for_condition(r\"amenity like '%taxi%' or public_transport like '%taxi%'\")\n",
    "bike_facilities = collect_features_for_condition(r\"amenity like '%bicycle%'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
