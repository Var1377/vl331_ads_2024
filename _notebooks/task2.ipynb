{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Urban Gentrification Through Infrastructure and Socioeconomic Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This research analyzes how public infrastructure, socioeconomic factors, and voting patterns can predict gentrification trends in urban areas. Using a data-driven approach, we'll examine:\n",
    "\n",
    "**Key Components:**\n",
    "- Public infrastructure data from OpenStreetMap (OSM)\n",
    "- Socioeconomic indicators from census data \n",
    "- Housing market dynamics from price paid data\n",
    "- Political trends from election results\n",
    "\n",
    "**Research Goals:**\n",
    "1. Establish a composite gentrification metric based on:\n",
    "   - Educational attainment changes\n",
    "   - Population turnover rates\n",
    "   - Index of Multiple Deprivation (IMD) shifts\n",
    "   - Demographic transitions\n",
    "   - Housing price acceleration\n",
    "\n",
    "2. Analyze correlations between:\n",
    "   - Public amenities (the \"Starbucks effect\")\n",
    "   - Transportation access\n",
    "   - Social indicators\n",
    "   - Political voting patterns\n",
    "   - Gentrification outcomes\n",
    "\n",
    "3. Build predictive models to:\n",
    "   - Identify areas at risk of future gentrification\n",
    "   - Quantify infrastructure impact on neighborhood change\n",
    "   - Map potential demographic transitions\n",
    "\n",
    "4. Provide insights for:\n",
    "   - Urban planning policy\n",
    "   - Community investment strategies\n",
    "   - Housing equity considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n",
      "Already downloaded lsoas.geojson\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import shapely as shp\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import fynesse\n",
    "import geopandas as gpd\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from zipfile import ZipFile\n",
    "import MySQLdb\n",
    "import sklearn\n",
    "import multiprocessing as mp\n",
    "import re\n",
    "\n",
    "# set up database connection\n",
    "\n",
    "%load_ext sql\n",
    "\n",
    "with open(\"./credentials1.yaml\") as file:\n",
    "  credentials = yaml.safe_load(file)\n",
    "\n",
    "username = credentials[\"username\"]\n",
    "password = credentials[\"password\"]\n",
    "url = credentials[\"url\"]\n",
    "port = credentials[\"port\"]\n",
    "\n",
    "%config SqlMagic.style = '_DEPRECATED_DEFAULT'\n",
    "\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{username}:{password}@{url}:{port}/ads_2024?local_infile=1\"\n",
    "%sql $connection_string\n",
    "%sql use ads_2024;\n",
    "\n",
    "conn = MySQLdb.connect(host=url, user=username, password=password, database=\"ads_2024\", local_infile=True)\n",
    "\n",
    "# download data\n",
    "# everything is on the scale of lsoas for data availability\n",
    "\n",
    "for url in [\n",
    "    (\"lsoas.geojson\", f\"https://open-geography-portalx-ons.hub.arcgis.com/api/download/v1/items/68515293204e43ca8ab56fa13ae8a547/geojson?layers=0\"),\n",
    "    \"https://www.getthedata.com/downloads/open_postcode_geo.csv.zip\",\n",
    "]:\n",
    "\n",
    "    if isinstance(url, tuple):\n",
    "        filename, url = url\n",
    "    else:\n",
    "        filename = f\"./{url.split('/')[-1]}\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {url}\")\n",
    "        r = requests.get(url)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Already downloaded {filename}\")\n",
    "\n",
    "\n",
    "    if filename.endswith('.zip') and not os.path.exists(filename.replace('.zip', '')):\n",
    "        with ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "0 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS lsoas (\n",
    "    year INT NOT NULL,\n",
    "    code VARCHAR(9) NOT NULL,\n",
    "    name VARCHAR(255) NOT NULL,\n",
    "\n",
    "    -- Geographic coordinates\n",
    "    bng_easting INT NOT NULL,              -- British National Grid Easting\n",
    "    bng_northing INT NOT NULL,             -- British National Grid Northing\n",
    "    latitude DECIMAL(10,8) NOT NULL,       -- Latitude coordinate\n",
    "    longitude DECIMAL(11,8) NOT NULL,      -- Longitude coordinate\n",
    "\n",
    "    -- Unique identifier\n",
    "    global_id VARCHAR(36) NOT NULL,\n",
    "\n",
    "    -- Geometry\n",
    "    geometry GEOMETRY NOT NULL,            -- Geometry of the output area in WG84\n",
    "    \n",
    "    -- Constraints\n",
    "    PRIMARY KEY (year, code)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varun\\AppData\\Local\\Temp\\ipykernel_70372\\326481068.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  if pd.read_sql(\"SELECT * from lsoas limit 1\", conn).empty:\n"
     ]
    }
   ],
   "source": [
    "if pd.read_sql(\"SELECT * from lsoas limit 1\", conn).empty:\n",
    "    if not os.path.exists(\"lsoas.csv\"):\n",
    "        gdf = gpd.read_file(\"lsoas.geojson\")\n",
    "        gdf.geometry.set_crs(epsg=27700, inplace=True)\n",
    "        gdf.geometry = gdf.geometry.to_crs(epsg=4326)\n",
    "        gdf.to_csv(\"lsoas.csv\", sep=\"|\", index=False)\n",
    "\n",
    "    command = \"\"\"\n",
    "    LOAD DATA LOCAL INFILE 'lsoas.csv'\\\n",
    "    INTO TABLE lsoas\\\n",
    "    FIELDS TERMINATED BY '|'\\\n",
    "    LINES TERMINATED BY '\\n'\\\n",
    "    IGNORE 1 LINES\\\n",
    "    (@fid, code, name, @welsh, bng_easting, bng_northing, latitude, longitude, global_id, @geometry)\\\n",
    "    SET year = 2021, geometry = ST_GeomFromText(@geometry);\"\"\"\n",
    "\n",
    "    %sql $command\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "fynesse.access.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS `pp_data` (\n",
    "  `transaction_unique_identifier` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `price` int(10) unsigned NOT NULL,\n",
    "  `date_of_transfer` date NOT NULL,\n",
    "  `postcode` varchar(8) COLLATE utf8_bin NOT NULL,\n",
    "  `property_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
    "  `new_build_flag` varchar(1) COLLATE utf8_bin NOT NULL,\n",
    "  `tenure_type` varchar(1) COLLATE utf8_bin NOT NULL,\n",
    "  `primary_addressable_object_name` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `secondary_addressable_object_name` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `street` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `locality` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `town_city` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `district` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `county` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `ppd_category_type` varchar(2) COLLATE utf8_bin NOT NULL,\n",
    "  `record_status` varchar(2) COLLATE utf8_bin NOT NULL,\n",
    "  `db_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT\n",
    "\n",
    "  -- Constraints\n",
    "  PRIMARY KEY (`db_id`)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin AUTO_INCREMENT=1 ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This code will take a long time to finish (i.e., more than 30 minutes) given our dataset's size. The print informs the uploading progress by year.\n",
    "if pd.read_sql(\"SELECT * from pp_data limit 1\", conn).empty:\n",
    "    for year in range(1996,2025):\n",
    "        print (\"Uploading data for year: \" + str(year))\n",
    "        for part in range(1,3):\n",
    "            file_name = \"./pp-\" + str(year) + \"-part\" + str(part) + \".csv\"\n",
    "            %sql LOAD DATA LOCAL INFILE '{file_name}' INTO TABLE pp_data FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED by '\"' LINES STARTING BY '' TERMINATED BY '\\n';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * mysql+pymysql://root:***@localhost:3306/ads_2024?local_infile=1\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Tables_in_ads_2024</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>census_nssec</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>hours_worked</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>lsoas</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>oas</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>osm_features</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('census_nssec',), ('hours_worked',), ('lsoas',), ('oas',), ('osm_features',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS `postcode_data` (\n",
    "  `postcode` varchar(8) COLLATE utf8_bin NOT NULL,\n",
    "  `status` enum('live','terminated') NOT NULL,\n",
    "  `usertype` enum('small', 'large') NOT NULL,\n",
    "  `easting` int unsigned,\n",
    "  `northing` int unsigned,\n",
    "  `positional_quality_indicator` int NOT NULL,\n",
    "  `country` enum('England', 'Wales', 'Scotland', 'Northern Ireland', 'Channel Islands', 'Isle of Man') NOT NULL,\n",
    "  `latitude` decimal(11,8) NOT NULL,\n",
    "  `longitude` decimal(10,8) NOT NULL,\n",
    "  `postcode_no_space` tinytext COLLATE utf8_bin NOT NULL,\n",
    "  `postcode_fixed_width_seven` varchar(7) COLLATE utf8_bin NOT NULL,\n",
    "  `postcode_fixed_width_eight` varchar(8) COLLATE utf8_bin NOT NULL,\n",
    "  `postcode_area` varchar(2) COLLATE utf8_bin NOT NULL,\n",
    "  `postcode_district` varchar(4) COLLATE utf8_bin NOT NULL,\n",
    "  `postcode_sector` varchar(6) COLLATE utf8_bin NOT NULL,\n",
    "  `outcode` varchar(4) COLLATE utf8_bin NOT NULL,\n",
    "  `incode` varchar(3)  COLLATE utf8_bin NOT NULL,\n",
    "  `db_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n",
    "\n",
    "  -- Constraints\n",
    "  PRIMARY KEY (`db_id`)\n",
    ") DEFAULT CHARSET=utf8 COLLATE=utf8_bin;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.read_sql(\"SELECT * from postcode_data limit 1\", conn).empty:\n",
    "    %sql LOAD DATA LOCAL INFILE \"./open_postcode_geo.csv\" INTO TABLE `postcode_data` FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED by '\"' LINES TERMINATED BY '\\n';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "MODIFY TABLE pp_data ADD INDEX idx_postcode (postcode), ADD INDEX idx_date_of_transfer (date_of_transfer);\n",
    "CREATE INDEX idx_postcode_data_postcode ON postcode_data(postcode);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
